#!/usr/bin/env python3
"""
Aster Buyback å¢é‡æ›´æ–°è„šæœ¬

æ ¸å¿ƒé€»è¾‘ï¼š
1. è¯»å–ä¸Šæ¬¡åŒæ­¥çŠ¶æ€ (last-sync.json)
2. åªæŸ¥è¯¢æ–°æ•°æ® (Moralis API)
3. åˆå¹¶åˆ°å†å²æ•°æ®
4. ä¿å­˜å¹¶æ›´æ–°åŒæ­¥çŠ¶æ€

ç”¨æ³•ï¼š
  python3 scripts/update-aster.py          # å¢é‡æ›´æ–°
  python3 scripts/update-aster.py --sync   # å¼ºåˆ¶å…¨é‡åŒæ­¥
"""

import subprocess
import json
import os
import sys
from datetime import datetime, timedelta
from pathlib import Path

# API Keys
MORALIS_API_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJub25jZSI6IjdmYWFmNTdkLTNiOWQtNGNhNS1hNGY3LTExZGI4Y2YyYzBlNiIsIm9yZ0lkIjoiNTAwNDkyIiwidXNlcklkIjoiNTE0OTg0IiwidHlwZUlkIjoiMjA4MzcyMWEtZmJjMC00NzQzLWEzNGItNGEyYmFlY2ExNTNlIiwidHlwZSI6IlBST0pFQ1QiLCJpYXQiOjE3NzA5OTIwNTMsImV4cCI6NDkyNjc1MjA1M30.Ef1yoypuIgSdnMMFnB9aFaDX6ILinqWuchJ8npxEZrA"

# Token and Wallets
ASTER_TOKEN = "0x000ae314e2a2172a039b26378814c252734f556a"
STAGE5_WALLET = "0x4786927333c0ba8ab27ca41361adf33148c5301e"
STAGE6_WALLET = "0x664827c71193018d7843f0d0f41a5d0d6dcebe0f"

# Paths
SCRIPT_DIR = Path(__file__).parent
DATA_DIR = SCRIPT_DIR / "../data"
BUYBACKS_FILE = DATA_DIR / "aster-buybacks.json"
ONCHAIN_FILE = DATA_DIR / "aster-onchain.json"
SYNC_STATE_FILE = DATA_DIR / "aster-last-sync.json"

# Stage 1-4 constants (historical, not changing)
STAGE14_TOTAL_ASTER = 143000000
STAGE14_TOTAL_USD = 214000000
STAGE14_DAYS = 56
STAGE14_START = "2025-10-28"
STAGE14_END = "2025-12-22"


def run_curl(url: str, headers: dict = None) -> dict:
    """ä½¿ç”¨ curl å‘é€è¯·æ±‚ï¼ˆé¿å… Python SSL é—®é¢˜ï¼‰"""
    cmd = ["curl", "-s", url]
    if headers:
        for k, v in headers.items():
            cmd.extend(["-H", f"{k}: {v}"])
    
    result = subprocess.run(cmd, capture_output=True, text=True)
    if result.returncode == 0:
        return json.loads(result.stdout)
    return {}


def load_sync_state() -> dict:
    """åŠ è½½åŒæ­¥çŠ¶æ€"""
    if SYNC_STATE_FILE.exists():
        with open(SYNC_STATE_FILE) as f:
            return json.load(f)
    return {"last_date": None, "last_block": None}


def save_sync_state(state: dict):
    """ä¿å­˜åŒæ­¥çŠ¶æ€"""
    state["updated_at"] = datetime.now().isoformat()
    with open(SYNC_STATE_FILE, "w") as f:
        json.dump(state, f, indent=2)


def load_onchain_data() -> list:
    """åŠ è½½é“¾ä¸Šæ•°æ®"""
    if ONCHAIN_FILE.exists():
        with open(ONCHAIN_FILE) as f:
            return json.load(f)
    return []


def save_onchain_data(data: list):
    """ä¿å­˜é“¾ä¸Šæ•°æ®"""
    with open(ONCHAIN_FILE, "w") as f:
        json.dump(data, f, indent=2)


def fetch_transfers_since(wallet: str, stage: str, from_date: str = None, from_block: int = None) -> list:
    """è·å–æŒ‡å®šæ—¥æœŸ/åŒºå—åçš„æ–°è½¬å…¥"""
    print(f"   Fetching {stage} transfers since {from_date or from_block}...")
    
    transfers = []
    cursor = None
    page = 0
    
    while True:
        page += 1
        url = f"https://deep-index.moralis.io/api/v2.2/{wallet}/erc20/transfers?chain=bsc&contract_addresses%5B0%5D={ASTER_TOKEN}&limit=100"
        if cursor:
            url += f"&cursor={cursor}"
        if from_block:
            url += f"&from_block={from_block}"
        
        headers = {"X-API-Key": MORALIS_API_KEY}
        data = run_curl(url, headers)
        
        if "result" not in data:
            print(f"   âš ï¸ API error: {data}")
            break
        
        # ç­›é€‰è½¬å…¥ï¼ˆto_address == walletï¼‰
        for tx in data["result"]:
            if tx["to_address"].lower() == wallet.lower():
                tx_date = tx["block_timestamp"][:10]
                
                # å¦‚æœæŒ‡å®šäº† from_dateï¼Œè·³è¿‡æ›´æ—©çš„æ•°æ®
                if from_date and tx_date < from_date:
                    continue
                
                amount = float(tx.get("value_decimal", 0) or 0)
                if amount > 0:
                    transfers.append({
                        "date": tx_date,
                        "amount": amount,
                        "block": int(tx["block_number"]),
                        "tx_hash": tx["transaction_hash"],
                        "stage": stage
                    })
        
        print(f"   Page {page}: {len(data['result'])} records")
        
        cursor = data.get("cursor")
        if not cursor:
            break
        if page >= 50:
            print("   Reached page limit")
            break
    
    return transfers


def aggregate_by_date(transfers: list, existing: list = None) -> list:
    """æŒ‰æ—¥æœŸèšåˆï¼Œåˆå¹¶åˆ°ç°æœ‰æ•°æ®"""
    from collections import defaultdict
    
    # ç°æœ‰æ•°æ®è½¬ä¸ºå­—å…¸
    existing_dict = {}
    if existing:
        for r in existing:
            existing_dict[r["date"]] = r
    
    # èšåˆæ–°æ•°æ®
    daily = defaultdict(lambda: {"aster": 0.0, "txs": 0, "stage": None, "max_block": 0})
    for tx in transfers:
        date = tx["date"]
        daily[date]["aster"] += tx["amount"]
        daily[date]["txs"] += 1
        daily[date]["stage"] = tx["stage"]
        daily[date]["max_block"] = max(daily[date]["max_block"], tx["block"])
    
    # åˆå¹¶åˆ°ç°æœ‰
    for date, d in daily.items():
        if date in existing_dict:
            # æ›´æ–°ç°æœ‰ï¼ˆå¯èƒ½æœ‰æ–°äº¤æ˜“ï¼‰
            existing_dict[date]["aster"] = round(d["aster"], 2)
            existing_dict[date]["txs"] = d["txs"]
        else:
            # æ·»åŠ æ–°æ—¥æœŸ
            existing_dict[date] = {
                "date": date,
                "aster": round(d["aster"], 2),
                "txs": d["txs"],
                "stage": d["stage"],
                "data_type": "onchain",
                "source": "moralis"
            }
    
    # è½¬å›åˆ—è¡¨å¹¶æ’åº
    result = list(existing_dict.values())
    result.sort(key=lambda x: x["date"])
    return result


def generate_stage14_data() -> list:
    """ç”Ÿæˆ Stage 1-4 ä¼°ç®—æ•°æ®"""
    from datetime import date, timedelta
    
    daily_aster = STAGE14_TOTAL_ASTER / STAGE14_DAYS
    daily_usd = STAGE14_TOTAL_USD / STAGE14_DAYS
    
    start = date.fromisoformat(STAGE14_START)
    result = []
    
    for i in range(STAGE14_DAYS):
        d = start + timedelta(days=i)
        result.append({
            "date": d.isoformat(),
            "aster": round(daily_aster),
            "usd": round(daily_usd),
            "stage": "1-4",
            "data_type": "estimated",
            "source": "Cryptopolitan"
        })
    
    return result


def merge_all_data(stage14: list, onchain: list) -> dict:
    """åˆå¹¶æ‰€æœ‰æ•°æ®åˆ°ä¸»æ–‡ä»¶"""
    all_data = stage14 + onchain
    
    # è®¡ç®—æ±‡æ€»
    stage14_sum = sum(r["aster"] for r in all_data if r.get("stage") == "1-4")
    stage5_sum = sum(r["aster"] for r in all_data if r.get("stage") == "stage5")
    stage6_sum = sum(r["aster"] for r in all_data if r.get("stage") == "stage6")
    
    return {
        "protocol": "aster",
        "ticker": "ASTER",
        "total_supply": 1000000000,
        "updated_at": datetime.now().isoformat(),
        "summary": {
            "total_buyback_aster": round(stage14_sum + stage5_sum + stage6_sum),
            "stage14_aster": round(stage14_sum),
            "stage14_usd": STAGE14_TOTAL_USD,
            "stage5_aster": round(stage5_sum),
            "stage6_aster": round(stage6_sum),
            "total_days": len(all_data),
            "note": "Stage 1-4 ä¸ºä¼°ç®— (Cryptopolitan), Stage 5-6 ä¸ºé“¾ä¸ŠçœŸå®æ•°æ® (Moralis API)"
        },
        "daily_buybacks": all_data
    }


def main():
    print("=" * 50)
    print("Aster Buyback å¢é‡æ›´æ–°")
    print(f"Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 50)
    
    full_sync = "--sync" in sys.argv
    
    # åŠ è½½åŒæ­¥çŠ¶æ€
    state = load_sync_state()
    print(f"\nğŸ“‹ ä¸Šæ¬¡åŒæ­¥: {state.get('last_date', 'æ— ')}")
    
    # åŠ è½½ç°æœ‰é“¾ä¸Šæ•°æ®
    onchain = load_onchain_data()
    print(f"   ç°æœ‰æ•°æ®: {len(onchain)} å¤©")
    
    if full_sync or not state.get("last_date"):
        print("\nğŸ”„ æ‰§è¡Œå…¨é‡åŒæ­¥...")
        
        # Stage 5
        print("\nğŸ“Š Stage 5:")
        s5_transfers = fetch_transfers_since(STAGE5_WALLET, "stage5")
        print(f"   è·å– {len(s5_transfers)} ç¬”äº¤æ˜“")
        
        # Stage 6
        print("\nğŸ“Š Stage 6:")
        s6_transfers = fetch_transfers_since(STAGE6_WALLET, "stage6")
        print(f"   è·å– {len(s6_transfers)} ç¬”äº¤æ˜“")
        
        all_transfers = s5_transfers + s6_transfers
        onchain = aggregate_by_date(all_transfers)
        
    else:
        print("\nğŸ“Š å¢é‡æ›´æ–°...")
        
        # åªè·å–æœ€æ–°æ—¥æœŸä¹‹åçš„æ•°æ®
        from_date = state["last_date"]
        
        # Stage 5 (å¦‚æœè¿˜åœ¨æ´»è·ƒ)
        s5_transfers = fetch_transfers_since(STAGE5_WALLET, "stage5", from_date=from_date)
        
        # Stage 6
        s6_transfers = fetch_transfers_since(STAGE6_WALLET, "stage6", from_date=from_date)
        
        new_transfers = s5_transfers + s6_transfers
        print(f"\n   æ–°å¢ {len(new_transfers)} ç¬”äº¤æ˜“")
        
        if new_transfers:
            onchain = aggregate_by_date(new_transfers, onchain)
    
    # ä¿å­˜é“¾ä¸Šæ•°æ®
    save_onchain_data(onchain)
    
    # æ›´æ–°åŒæ­¥çŠ¶æ€
    if onchain:
        latest_date = max(r["date"] for r in onchain)
        save_sync_state({"last_date": latest_date})
        print(f"\nâœ… åŒæ­¥çŠ¶æ€å·²æ›´æ–°: {latest_date}")
    
    # ç”Ÿæˆ Stage 1-4 æ•°æ®
    stage14 = generate_stage14_data()
    
    # åˆå¹¶å¹¶ä¿å­˜ä¸»æ–‡ä»¶
    result = merge_all_data(stage14, onchain)
    with open(BUYBACKS_FILE, "w") as f:
        json.dump(result, f, indent=2, ensure_ascii=False)
    
    # è¾“å‡ºæ±‡æ€»
    print(f"\nğŸ“Š æ±‡æ€»:")
    print(f"   Stage 1-4: {result['summary']['stage14_aster']:,} ASTER (ä¼°ç®—)")
    print(f"   Stage 5: {result['summary']['stage5_aster']:,} ASTER (é“¾ä¸Š)")
    print(f"   Stage 6: {result['summary']['stage6_aster']:,} ASTER (é“¾ä¸Š)")
    print(f"   æ€»è®¡: {result['summary']['total_buyback_aster']:,} ASTER")
    print(f"   å æ¯”: {result['summary']['total_buyback_aster'] / 1e9 * 100:.2f}%")
    print(f"\nâœ… å·²ä¿å­˜åˆ° {BUYBACKS_FILE}")


if __name__ == "__main__":
    main()
